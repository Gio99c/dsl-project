{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from Preprocessing import  load, cleaning, text_mining_tfdf, text_mining_sentiment, preprocessing, create_public_holiday, hashtag_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief description of the two function that I have implemented:\n",
    " 1) compare_models --> train and test the models contained in the model list and create a dataframe to easily visualize the metrics \n",
    " 2) compare_models_KF --> do exactly the same, but it uses the K-Fold method to make robust result of the metrcs that we obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series, models: list, names: list) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"Inputs:\n",
    "        X_train = training data set\n",
    "        X_test = testing data set\n",
    "        y_train = training label \n",
    "        y_test = testing label \n",
    "        models = list of models to compare\n",
    "        names = list of trings containing the names of the models \n",
    "\n",
    "        Return: comparison table \n",
    "        \"\"\"\n",
    "\n",
    "    f1_scores, precision_scores, recall_scores, accuracy_scores = [], [], [],[]\n",
    "    \n",
    "    for clf, name in zip(models, names):\n",
    "\n",
    "        print(f'Start training model: {name}')\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        print('\\n')\n",
    "\n",
    "        finish_time = time.time()\n",
    "\n",
    "        print(f'Finishing training model: {name}, trained in {finish_time-start_time}\\n')\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracy_scores.append(acc)\n",
    "\n",
    "        prec = precision_score(y_test, y_pred, average = 'macro')\n",
    "        precision_scores.append(prec)\n",
    "\n",
    "        rec = recall_score(y_test, y_pred, average='macro')\n",
    "        recall_scores.append(rec)\n",
    "\n",
    "\n",
    "\n",
    "        print(f'Score of {name} model performed: {f1}')\n",
    "\n",
    "    col1 = pd.Series(names)\n",
    "    col2 = pd.Series(f1_scores)\n",
    "    col3 = pd.Series(recall_scores)\n",
    "    col4 = pd.Series(accuracy_scores)\n",
    "    col5 = pd.Series(precision_scores)\n",
    "\n",
    "    result = pd.concat([col1, col2, col3, col4, col5], axis = 'columns')\n",
    "    result.columns = ['Model Name', 'F1 Score', 'Recall', 'Accuray', 'Precision']\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_KF(X: pd.DataFrame, y: pd.Series, models: list, names: list, k = int) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"Inputs:\n",
    "        X = training data set\n",
    "        y = training label  \n",
    "        models = list of models to compare\n",
    "        names = list of trings containing the names of the models \n",
    "        k = int for the cross validation \n",
    "\n",
    "        Return: comparison table \n",
    "        \"\"\"\n",
    "\n",
    "    f1_scores = []\n",
    "    \n",
    "    for clf, name in zip(models, names):\n",
    "\n",
    "        print(f'Start training model: {name}')\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        f1_score = cross_val_score(clf, X, y, cv = k, scoring = 'f1_macro')\n",
    "\n",
    "        finish_time = time.time()\n",
    "\n",
    "        print(f'Finishing training model: {name}, trained in {finish_time-start_time}\\n')\n",
    "\n",
    "        f1 = f1_score.mean()\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        print(f'Score of {name} model performed: {f1}')\n",
    "\n",
    "    col1 = pd.Series(names)\n",
    "    col2 = pd.Series(f1_scores)\n",
    "    \n",
    "\n",
    "    result = pd.concat([col1, col2], axis = 'columns')\n",
    "    result.columns = ['Model Name', 'F1 Score']\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:00<00:00, 166.31it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 5447.52it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 5502.72it/s]\n",
      "/Users/gio/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "clf_models = [DecisionTreeClassifier(), KNeighborsClassifier(), SVC(), RandomForestClassifier(), GaussianNB(), MLPClassifier()]\n",
    "\n",
    "clf_names = ['Decision Tree', 'K-Nearest Neighbor', 'Support Vector Machine', 'Random Forest', 'Nayve Bayes', 'Multi Layer Neural Network']\n",
    "\n",
    "X, y = load().pipe(cleaning).pipe(create_public_holiday).pipe(text_mining_sentiment).pipe(text_mining_tfdf).pipe(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: Decision Tree\n",
      "\n",
      "\n",
      "Finishing training model: Decision Tree, trained in 0.30092501640319824\n",
      "\n",
      "Score of Decision Tree model performed: 0.7058956608298266\n",
      "Start training model: K-Nearest Neighbor\n",
      "\n",
      "\n",
      "Finishing training model: K-Nearest Neighbor, trained in 0.004374980926513672\n",
      "\n",
      "Score of K-Nearest Neighbor model performed: 0.666065963031506\n",
      "Start training model: Support Vector Machine\n",
      "\n",
      "\n",
      "Finishing training model: Support Vector Machine, trained in 6.308397054672241\n",
      "\n",
      "Score of Support Vector Machine model performed: 0.7613605232518321\n",
      "Start training model: Random Forest\n",
      "\n",
      "\n",
      "Finishing training model: Random Forest, trained in 1.6253759860992432\n",
      "\n",
      "Score of Random Forest model performed: 0.769748995006693\n",
      "Start training model: Nayve Bayes\n",
      "\n",
      "\n",
      "Finishing training model: Nayve Bayes, trained in 0.019955873489379883\n",
      "\n",
      "Score of Nayve Bayes model performed: 0.6897568914657715\n",
      "Start training model: Multi Layer Neural Network\n",
      "\n",
      "\n",
      "Finishing training model: Multi Layer Neural Network, trained in 8.674783945083618\n",
      "\n",
      "Score of Multi Layer Neural Network model performed: 0.7338535458352328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gio/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y)\n",
    "\n",
    "df_result = compare_models(X_train= X_train, X_test= X_test, y_test=y_test, y_train=y_train, models= clf_models, names= clf_names)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
