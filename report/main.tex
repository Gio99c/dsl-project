\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{booktabs}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{tablefootnote}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{svg}
\graphicspath{ {./figures/} }
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\usepackage[autostyle]{csquotes}
\begin{document}

\title{Twitter Sentiment Analysis Classification}

\author{\IEEEauthorblockN{Giuseppe Concialdi}
\IEEEauthorblockA{\textit{Politecnico di Torino} \\
Student id: s294666 \\
giuseppe.concialdi@studenti.polito.it}
\and
\IEEEauthorblockN{Christian Montecchiani}
\IEEEauthorblockA{\textit{Politecnico di Torino} \\
Student id: s303681 \\
christian.montecchiani@studenti.polito.it}
}

\maketitle

\begin{abstract}
 
\end{abstract}

\section{Problem overview}\label{sec:overview}
The objective of the competition was to build a model that is able to classify whether a tweets contains positive or negative sentiments. The dataset provided is arranged as follow:
\begin{itemize}
    \item A \textbf{development} set composed by 224,994 records of tweets. Each sample has six different features, including the \textit{sentiment} attribute that is the target the classification.
    \item A \textbf{evaluation} set consisting of 74,999 samples. Its dimension is one-third of the development set and it does not feature the target variable.
\end{itemize}
The dataset is quite large, so the time required to manage the operations on the data should be taken into account because it could be not trivial. It is essential to retrieve some meaningful information of the data by exploiting its features. In particular, every sample is characterized by:
\begin{itemize}
    \item \textit{ids}: the unique identifier of the tweet. It is represented by a progressive integer number that is related to the timestamp of the tweet. The lowest value of the \textit{ids} attribute is 1,467,811,193 while the highest is 2,329,205,038. It is uncertain if the dataset includes only a subset of the actual number of posted tweets or if the increase of the values follows some pattern. In fact, by digging in the past twitter documentation, we found out that the tweet id is generated with a snowflake schema, invented by Twitter for the generation of sequential ids for their tweets.
    \item \textit{date}: the timestamp of each tweet. The date is encoded as a string not in the ISO 8601 standard\cite{iso8601} but with the format:
    $$weekday \quad month \quad day \quad hour:min:sec \quad tz \quad year$$
    From this schema, the information can be easily extracted and exploited to train the model. The dates in the dataset range from April 6 to June 25 of 2009. Knowing the temporal ranges will help during the preprocessing phase.
    \item \textit{flag}: a string whose significance is unsure. It is present in the whole dataset with the unique value of "NO\_QUERY". Given its absence of meaning, this feature will be removed without a second thought, but it is possible that it would report the query used to retrieve the tweets when they were extracted using some Twitter APIs.
    \item \textit{user}: the username of the creator of the tweet. Even though there are almost 225 thousand tweets, there are only 10,647 different usernames. Therefore, on average, the users are very active and they have probably posted several tweets in this period.
    \item \textit{text}: the text of the tweet. This is the core part of the analysis, it embodies a lot of insights that can be extracted and analyzed to retrieve the overall polarity of the tweet's sentiments. In 2009 the maximum length of a tweet was 140 characters\cite{tweet_lenght}. However, some tweets exceed this threshold, so there are likely issues with the encoding of the text extracted.
    \item \textit{sentiment}: the target variable of the classification. It assumes two possible integer values: 0 and 1 that represent respectively negative and positive sentiments. The dataset is fairly unbalanced, as shown in figure \ref{fig:unbalanced}, there are more positive sentiments than negative ones.
\end{itemize}
In the \ref{sec:approach} we will assess what are the most relevant features to carry on the classification and how we will extract the relevant information that lies within each feature.

\section{Proposed approach}\label{sec:approach}
The dataset does not feature any missing value, but it contains redundant information that is useless for the analysis. We decided to extract the time-related information from the \textit{date} attribute. In this manner, we added new features to the dataset and also some aggregated measures like the time of the day (morning, afternoon, night) and the time of the time (workday, weekend) during which the tweet was posted. At this stage was still unknown whether all this attributes extracted from the \textit{date} variable would have been useful or not. That is because the \textit{ids} feature is not useless, but it already encodes the timestamp of the tweet. Nonetheless, we decided to leave those features and figure out later if their relative importance would matter.

Although the \textit{date} attribute could hide some useful insights about the sentiment of the tweet, the major knowledge lies within the \textit{text} attribute. The information extraction from this feature can be performed in different ways and with different processes. We decided to tackle the problem from different points of view and we managed to embed all this data into our model. Firstly, we cleaned up and fix some problems present in the tweets' text, then we exploited the text performing:
\begin{itemize}
    \item A \textbf{sentiment intensity analysis}\cite{} on the text, obtaining new features on the polarization of the sentiments.
    \item A \textbf{tf-df}\cite{} of the text in order to get the words that mainly influence the sentiments of the tweets.
    \item A \textbf{word embedding}\cite{} approach with the FastText\cite{} library to retrieve the morphological relationships between the words in a sentence.
\end{itemize}
Figure \ref{fig:text_mining} shows a summary of our approach.
The last technique resulted in a very powerful tool, that is able, on its own, to perform the classification of the sentiment of the evaluation set with an f1-score\cite{f1} higher than 0.8. This was our baseline for the development of the model, and we accomplished higher performance by integrating the likelihoods of the FastText supervised learning classification to our dataset. 

Finally, we wanted to add the \textit{user} attribute into the equation. We thought that due to the relative low cardinality of this attribute (only 10,000 different usernames) the tweets posted by the same author may reflect its personality, thus it is probable that a sentiment is predominant with respect to the other one. We did not want to encode the information of each user because of the subsequent dimensionality increase of the the dataset with an approach like the One-Hot-Encoding\cite{ohe}. \textbf{***to rephrase}
So we chose to incorporate the user author of the post at the beginning of the text of the tweet. The text already contains mentioned user whose name is preceded by an at-sign (@). In this way, the word embedding classification will retrieve information about the author of the post like if he was mentioned within it.

Sections \ref{sec:preprocessing} and \ref{sec:model} will dig into the details of the three different text mining techniques and some comments about the word embedding can be found in the Discussion section \ref{sec:discussion} of the paper.

\subsection{Preprocessing}\label{sec:preprocessing}
\subsection{Model selection}\label{sec:model}
\subsection{Hyperparameters tuning}\label{sec:hypertuning}

\section{Results}\label{sec:results}
Here you will present your results (models \& configurations selected, performance achieved)

\section{Discussion}\label{sec:discussion}
Any relevant discussion goes here.

\bibliography{bibliography}
\bibliographystyle{ieeetr}

\end{document}
